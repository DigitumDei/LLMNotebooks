{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install pydub\n",
    "%pip install ffmpeg-downloader\n",
    "%ffdl install --add-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6595c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "ffmpeg_path = os.getenv(\"FFMPEG_PATH\")\n",
    "ffprobe_path = os.getenv(\"FFPROBE_PATH\")\n",
    "\n",
    "if ffmpeg_path:\n",
    "    print(f\"Setting pydub.AudioSegment.ffmpeg to: {ffmpeg_path}\")\n",
    "    AudioSegment.ffmpeg = ffmpeg_path\n",
    "\n",
    "    # pydub often infers ffprobe from the ffmpeg path,\n",
    "    # but you can set it explicitly if needed or if it's in a different location.\n",
    "    # ffprobe_path from .env (if set) takes precedence.\n",
    "\n",
    "    # Determine the potential inferred ffprobe path more robustly\n",
    "    _inferred_ffprobe_base = os.path.join(os.path.dirname(ffmpeg_path), \"ffprobe\")\n",
    "    _actual_inferred_ffprobe_path = _inferred_ffprobe_base\n",
    "    # On Windows, check for .exe if the plain name doesn't exist and ffmpeg_path was likely a dir or plain name\n",
    "    if os.name == 'nt' and \\\n",
    "       not os.path.exists(_actual_inferred_ffprobe_path) and \\\n",
    "       os.path.exists(_inferred_ffprobe_base + \".exe\"):\n",
    "        _actual_inferred_ffprobe_path = _inferred_ffprobe_base + \".exe\"\n",
    "    \n",
    "    _inferred_ffprobe_exists = os.path.exists(_actual_inferred_ffprobe_path)\n",
    "\n",
    "    if not ffprobe_path and _inferred_ffprobe_exists:\n",
    "        AudioSegment.ffprobe = _actual_inferred_ffprobe_path\n",
    "        print(f\"Setting pydub.AudioSegment.ffprobe to: {_actual_inferred_ffprobe_path} (inferred alongside ffmpeg)\")\n",
    "    elif ffprobe_path:\n",
    "        AudioSegment.ffprobe = ffprobe_path\n",
    "        print(f\"Setting pydub.AudioSegment.ffprobe to: {ffprobe_path} (from FFPROBE_PATH)\")\n",
    "    else: # This case means ffprobe_path was not set AND the inferred path also does not exist.\n",
    "        print(f\"Info: FFPROBE_PATH not set and ffprobe not found alongside ffmpeg. pydub will search system PATH for ffprobe.\")\n",
    "else:\n",
    "    print(\"FFMPEG_PATH not found in .env. pydub will try to find ffmpeg in the system PATH.\")\n",
    "    print(\"Info: pydub will also try to find ffprobe in the system PATH.\")\n",
    "\n",
    "def split_audio_with_overlap(\n",
    "    m4a_file_path: str,\n",
    "    chunk_length_min: float = 2.0,\n",
    "    overlap_sec: float = 5.0,\n",
    "    output_dir: str = \"audio_chunks\"\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Splits an M4A audio file into smaller chunks with a specified overlap.\n",
    "\n",
    "    Args:\n",
    "        m4a_file_path (str): Path to the input M4A audio file.\n",
    "        chunk_length_min (float): Desired length of each chunk in minutes.\n",
    "                                  Default is 2 minutes.\n",
    "        overlap_sec (float): Desired overlap between chunks in seconds.\n",
    "                             Default is 5 seconds.\n",
    "        output_dir (str): Directory to save the output chunk files.\n",
    "                          It will be created if it doesn't exist.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of absolute paths to the created chunk files.\n",
    "                   Returns an empty list if an error occurs or no chunks are made.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(m4a_file_path):\n",
    "        print(f\"Error: Audio file not found or is not a file: {m4a_file_path}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading audio file: {m4a_file_path}...\")\n",
    "        audio = AudioSegment.from_file(m4a_file_path, format=\"m4a\")\n",
    "        print(\"Audio file loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file '{m4a_file_path}': {e}\")\n",
    "        print(\"Please ensure FFmpeg is installed and accessible in your system's PATH.\")\n",
    "        print(\"You can download FFmpeg from https://ffmpeg.org/download.html\")\n",
    "        return []\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        try:\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"Created output directory: {output_dir}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating output directory '{output_dir}': {e}\")\n",
    "            return []\n",
    "    \n",
    "    chunk_length_ms = int(chunk_length_min * 60 * 1000)\n",
    "    overlap_ms = int(overlap_sec * 1000)\n",
    "\n",
    "    if chunk_length_ms <= 0:\n",
    "        print(\"Error: Chunk length must be positive.\")\n",
    "        return []\n",
    "    if overlap_ms < 0:\n",
    "        print(\"Error: Overlap must be non-negative.\")\n",
    "        return []\n",
    "    if chunk_length_ms <= overlap_ms and chunk_length_ms > 0 : # overlap can be 0\n",
    "        print(f\"Warning: Chunk length ({chunk_length_ms/1000}s) is not greater than overlap ({overlap_ms/1000}s). \"\n",
    "              \"This might lead to unexpected behavior or very short effective steps.\")\n",
    "        # Allow proceeding if user intends this, but it's unusual.\n",
    "\n",
    "    total_duration_ms = len(audio)\n",
    "    if total_duration_ms == 0:\n",
    "        print(\"Error: Audio file is empty.\")\n",
    "        return []\n",
    "        \n",
    "    print(f\"Total audio duration: {total_duration_ms / 1000:.2f} seconds.\")\n",
    "    print(f\"Target chunk length: {chunk_length_ms / 1000:.2f} seconds.\")\n",
    "    print(f\"Overlap: {overlap_ms / 1000:.2f} seconds.\")\n",
    "\n",
    "    chunk_files = []\n",
    "    start_ms = 0\n",
    "    chunk_id = 0\n",
    "    \n",
    "    while start_ms < total_duration_ms:\n",
    "        end_ms = start_ms + chunk_length_ms\n",
    "        # Ensure the chunk doesn't go past the end of the audio\n",
    "        actual_end_ms = min(end_ms, total_duration_ms)\n",
    "        \n",
    "        # This condition ensures we don't process an empty slice if start_ms somehow reaches total_duration_ms\n",
    "        if start_ms >= actual_end_ms: \n",
    "            break \n",
    "\n",
    "        current_chunk_duration_ms = actual_end_ms - start_ms\n",
    "        print(f\"Processing chunk {chunk_id:03d}: \"\n",
    "              f\"Start: {start_ms/1000:.2f}s, End: {actual_end_ms/1000:.2f}s, \"\n",
    "              f\"Duration: {current_chunk_duration_ms/1000:.2f}s\")\n",
    "\n",
    "        chunk = audio[start_ms:actual_end_ms]\n",
    "        \n",
    "        # Sanity check for very small chunks, especially if they are smaller than overlap\n",
    "        # (though the transcription service might handle this fine)\n",
    "        if current_chunk_duration_ms < 100: # e.g. less than 0.1 seconds\n",
    "            print(f\"  Skipping very short chunk {chunk_id:03d} (duration < 0.1s).\")\n",
    "            if actual_end_ms == total_duration_ms: # If it was the last bit\n",
    "                break\n",
    "            start_ms += (chunk_length_ms - overlap_ms)\n",
    "            if chunk_length_ms - overlap_ms <= 0 and chunk_length_ms > 0 : # Avoid infinite loop if step is not positive\n",
    "                 print(\"Warning: Effective step is not positive due to overlap >= chunk_length. Stopping.\")\n",
    "                 break\n",
    "            continue\n",
    "\n",
    "\n",
    "        output_filename = f\"chunk_{chunk_id:03d}.m4a\"\n",
    "        # Use absolute path for output_dir to ensure chunk_files contains absolute paths\n",
    "        abs_output_dir = os.path.abspath(output_dir)\n",
    "        output_path = os.path.join(abs_output_dir, output_filename)\n",
    "        \n",
    "        try:\n",
    "            export_params = [\"-strict\", \"experimental\"]\n",
    "            print(f\"  Exporting with codec='aac', bitrate='128k', params={export_params} to: {output_path}\")\n",
    "            chunk.export(output_path,\n",
    "                         format=\"mp4\",\n",
    "                         codec=\"aac\",\n",
    "                         bitrate=\"128k\",\n",
    "                         parameters=export_params)\n",
    "            chunk_files.append(output_path)\n",
    "            print(f\"  Exported: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error exporting chunk {output_path}: {e}\")\n",
    "            # Optionally, decide if you want to stop or continue if a single chunk fails\n",
    "        \n",
    "        chunk_id += 1\n",
    "        \n",
    "        # If this chunk already processed up to the end of the audio, no more chunks needed.\n",
    "        if actual_end_ms == total_duration_ms:\n",
    "            print(\"Reached end of audio.\")\n",
    "            break \n",
    "            \n",
    "        next_start_ms = start_ms + (chunk_length_ms - overlap_ms)\n",
    "\n",
    "        # If the step (chunk_length_ms - overlap_ms) is zero or negative,\n",
    "        # and we haven't reached the end, we'd loop infinitely.\n",
    "        if next_start_ms <= start_ms and actual_end_ms < total_duration_ms:\n",
    "            print(f\"Error: Advancing start_ms from {start_ms} to {next_start_ms} would not progress or would go backward. \"\n",
    "                  \"This usually means overlap is too large relative to chunk length. Stopping.\")\n",
    "            break\n",
    "        \n",
    "        start_ms = next_start_ms\n",
    "\n",
    "    if not chunk_files:\n",
    "        print(\"No chunks were created. This might be due to a very short audio file or configuration issues.\")\n",
    "    else:\n",
    "        print(f\"\\nSuccessfully created {len(chunk_files)} chunks in '{os.path.abspath(output_dir)}'.\")\n",
    "    return chunk_files\n",
    "\n",
    "# --- Example Usage (you can run this in a separate cell or script) ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Create a dummy M4A file for testing if you don't have one readily available\n",
    "#     # This requires FFmpeg to be installed and working with pydub.\n",
    "#     # print(\"Attempting to create a dummy M4A file for testing...\")\n",
    "#     # try:\n",
    "#     #     # 4.5 minutes of silence\n",
    "#     #     duration_ms = int(4.5 * 60 * 1000) \n",
    "#     #     silence = AudioSegment.silent(duration=duration_ms) \n",
    "#     #     dummy_file_path = \"dummy_long_audio.m4a\"\n",
    "#     #     silence.export(dummy_file_path, format=\"m4a\")\n",
    "#     #     print(f\"Dummy M4A file created at: {dummy_file_path}\")\n",
    "#     #     input_audio_file = dummy_file_path\n",
    "#     # except Exception as e:\n",
    "#     #     print(f\"Could not create dummy M4A file: {e}\")\n",
    "#     #     print(\"Please ensure FFmpeg is installed and pydub can use it.\")\n",
    "#     #     print(\"Using a placeholder for input_audio_file. Replace it with your actual file.\")\n",
    "#     #     input_audio_file = \"REPLACE_WITH_YOUR_LONG_AUDIO.m4a\" # Placeholder\n",
    "#\n",
    "#     # --- Replace with the path to YOUR M4A file ---\n",
    "#     input_audio_file = \"REPLACE_WITH_YOUR_LONG_AUDIO.m4a\" \n",
    "#     # Example: input_audio_file = \"/path/to/my/long_recording.m4a\"\n",
    "#     # Example: input_audio_file = \"C:/Users/YourName/Music/long_interview.m4a\"\n",
    "#\n",
    "#     if input_audio_file == \"REPLACE_WITH_YOUR_LONG_AUDIO.m4a\" or not os.path.exists(input_audio_file):\n",
    "#         print(f\"\\n--- PLEASE READ ---\")\n",
    "#         print(f\"The example is currently set to use a placeholder file: '{input_audio_file}'.\")\n",
    "#         print(f\"Please replace this with the actual path to your long M4A audio file to test the splitting function.\")\n",
    "#         print(f\"If you uncommented the dummy file creation, ensure it was successful.\")\n",
    "#         print(f\"-------------------\")\n",
    "#     else:\n",
    "#         print(f\"\\nStarting audio splitting process for: {input_audio_file}\")\n",
    "#         # Split into 2-minute chunks with 5-second overlap\n",
    "#         created_chunk_paths = split_audio_with_overlap(\n",
    "#             input_audio_file,\n",
    "#             chunk_length_min=2.0,\n",
    "#             overlap_sec=5.0,\n",
    "#             output_dir=\"my_split_audio_chunks\" \n",
    "#         )\n",
    "#\n",
    "#         if created_chunk_paths:\n",
    "#             print(\"\\nList of created chunk files:\")\n",
    "#             for path in created_chunk_paths:\n",
    "#                 print(path)\n",
    "#             # Now you can iterate through created_chunk_paths and send each to your transcription function\n",
    "#         else:\n",
    "#             print(\"\\nAudio splitting process completed, but no chunk files were generated.\")\n",
    "#\n",
    "#     # To clean up the dummy file and directory if you created them:\n",
    "#     # if os.path.exists(\"dummy_long_audio.m4a\"):\n",
    "#     #     os.remove(\"dummy_long_audio.m4a\")\n",
    "#     # if os.path.exists(\"my_split_audio_chunks\"):\n",
    "#     #     import shutil\n",
    "#     #     shutil.rmtree(\"my_split_audio_chunks\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5524c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys # Still useful for stderr in case of errors within the function\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "transcriptions_list = []\n",
    "\n",
    "def transcribe_audio_notebook(api_key: str, audio_file_path: str, model: str = \"gpt-4o-mini-transcribe\") -> str | None:\n",
    "    \"\"\"\n",
    "    Transcribes an audio file using OpenAI's Whisper model.\n",
    "    Suitable for use in a Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): The OpenAI API key.\n",
    "        audio_file_path (str): The path to the audio file.\n",
    "        model (str): The model to use for transcription (default: \"gpt-4o-mini-transcribe\").\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed text, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        print(\"Error: OpenAI API key is missing. Please provide a valid API key.\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "        print(f\"Opening audio file: {audio_file_path}\")\n",
    "        created_chunk_paths = split_audio_with_overlap(\n",
    "             audio_file_path,\n",
    "             chunk_length_min=2.0,\n",
    "             overlap_sec=5.0,\n",
    "             output_dir=\"my_split_audio_chunks\" \n",
    "         )\n",
    "        for chunk_f in created_chunk_paths:\n",
    "            with open(chunk_f, \"rb\") as audio_file:\n",
    "                print(f\"Sending audio to OpenAI API using model: {model}...\")\n",
    "                transcription = client.audio.transcriptions.create(\n",
    "                    model=model,\n",
    "                    file=audio_file\n",
    "                )\n",
    "                print(\"\\ntranscription.text\")\n",
    "                transcriptions_list.append(transcription.text)\n",
    "\n",
    "        print(\"Transcription received from API.\")\n",
    "        return transcription.text\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"OpenAI API Connection Error: {e}\", file=sys.stderr)\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI API Rate Limit Error: {e}\", file=sys.stderr)\n",
    "    except openai.AuthenticationError as e:\n",
    "        print(f\"OpenAI API Authentication Error: {e}\", file=sys.stderr)\n",
    "        print(\"Please check your API key.\", file=sys.stderr)\n",
    "    except openai.APIStatusError as e:\n",
    "        print(f\"OpenAI API Status Error (HTTP Status {e.status_code}): {e.message}\", file=sys.stderr)\n",
    "        if hasattr(e, 'response') and e.response and hasattr(e.response, 'content'):\n",
    "            try:\n",
    "                print(f\"Response body: {e.response.content.decode()}\", file=sys.stderr)\n",
    "            except Exception:\n",
    "                print(f\"Response body (raw): {e.response.content}\", file=sys.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Audio file not found at {audio_file_path}\", file=sys.stderr)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n",
    "    return None\n",
    "\n",
    "# --- Example Usage in a Jupyter Notebook Cell ---\n",
    "\n",
    "# 1. Set your OpenAI API Key\n",
    "# Option A: Retrieve from environment variable (if set before starting Jupyter)\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Option B: Paste your API key directly (less secure, especially if sharing the notebook)\n",
    "# my_api_key = \"sk-your_actual_api_key_here\"\n",
    "\n",
    "# Option C: Prompt for the API key (more secure if typing it in)\n",
    "# import getpass\n",
    "# if not my_api_key: # If not found in environment\n",
    "#     my_api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "if not my_api_key:\n",
    "    print(\"API Key not found. Please set it via environment variable or directly in the script.\", file=sys.stderr)\n",
    "    # sys.exit(1) # In a notebook, you might just let it fail or handle differently\n",
    "else:\n",
    "    # 2. Specify the path to your audio file\n",
    "    audio_path = \"C:\\\\Users\\\\Hydra\\\\Downloads\\\\Voice 241228_104608.m4a\"\n",
    "    # e.g., audio_path = \"/path/to/your/audio.wav\"\n",
    "\n",
    "    #gpt-4o-transcribe\n",
    "    #gpt-4o-mini-transcribe\n",
    "    #whisper-1\n",
    "\n",
    "    model_to_use = \"gpt-4o-mini-transcribe\"\n",
    "\n",
    "    print(f\"\\nAttempting to transcribe '{audio_path}' using model '{model_to_use}'...\")\n",
    "    \n",
    "    # 4. Call the transcription function\n",
    "    transcribed_text = transcribe_audio_notebook(my_api_key, audio_path, model=model_to_use)\n",
    "\n",
    "    # 5. Print the result\n",
    "    if transcriptions_list:\n",
    "        print(\"\\nTranscription successfull, please run next step\")\n",
    "    else:\n",
    "        print(\"\\nTranscription failed. Please check the error messages above.\", file=sys.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys # For stderr\n",
    "\n",
    "# (Ensure you've already run !pip install openai in a previous cell if needed)\n",
    "\n",
    "def summarize_text_openai(api_key: str, text_to_summarize: str, model: str = \"gpt-3.5-turbo\") -> str | None:\n",
    "    \"\"\"\n",
    "    Summarizes a given text using OpenAI's Chat Completions API.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): The OpenAI API key.\n",
    "        text_to_summarize (str): The text content to be summarized.\n",
    "        model (str): The OpenAI model to use for summarization (e.g., \"gpt-3.5-turbo\", \"gpt-4\").\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        print(\"Error: OpenAI API key is missing. Please provide a valid API key.\", file=sys.stderr)\n",
    "        return None\n",
    "    if not text_to_summarize.strip():\n",
    "        print(\"Error: Text to summarize is empty.\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        \n",
    "        # Constructing the prompt for summarization\n",
    "        # You can customize the system message and user prompt for different summary styles or lengths.\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You must summarise the provided transcription, trying to include all information given, keeping the summary in time order as much as possible. For instance if dealing with bee hive maintenance, try summarise by frame number in a hive etc. Each box contains 10 frames, some hives have honey super boxes as well as brood boxes. We will have tried to mention frame number when doing them, and mentioned what box we are looking at.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize the following transcript:\\n\\n{text_to_summarize}\"}\n",
    "        ]\n",
    "\n",
    "        print(f\"Sending text to OpenAI API for summarization using model: {model}...\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.5,  # Lower temperature for more focused summaries\n",
    "            max_tokens=10000   \n",
    "        )\n",
    "        \n",
    "        summary = response.choices[0].message.content\n",
    "        print(\"Summary received from API.\")\n",
    "        return summary.strip()\n",
    "\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"OpenAI API Connection Error: {e}\", file=sys.stderr)\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI API Rate Limit Error: {e}\", file=sys.stderr)\n",
    "    except openai.AuthenticationError as e:\n",
    "        print(f\"OpenAI API Authentication Error: {e}\", file=sys.stderr)\n",
    "        print(\"Please check your API key.\", file=sys.stderr)\n",
    "    except openai.APIStatusError as e:\n",
    "        print(f\"OpenAI API Status Error (HTTP Status {e.status_code}): {e.message}\", file=sys.stderr)\n",
    "        if hasattr(e, 'response') and e.response and hasattr(e.response, 'content'):\n",
    "            try:\n",
    "                print(f\"Response body: {e.response.content.decode()}\", file=sys.stderr)\n",
    "            except Exception:\n",
    "                print(f\"Response body (raw): {e.response.content}\", file=sys.stderr)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during summarization: {e}\", file=sys.stderr)\n",
    "    return None\n",
    "\n",
    "# --- Example Usage in a Jupyter Notebook Cell ---\n",
    "\n",
    "# Assuming 'transcriptions_list' is already populated from your previous transcription steps.\n",
    "# For demonstration, let's create a sample transcriptions_list:\n",
    "# transcriptions_list = [\n",
    "#     \"The first part of the meeting discussed quarterly earnings, which were above expectations.\",\n",
    "#     \"Then, the team moved on to new product development, highlighting the upcoming X1 model.\",\n",
    "#     \"Finally, there was a brief Q&A session addressing marketing strategies for the next fiscal year.\"\n",
    "# ]\n",
    "# Make sure transcriptions_list is defined and populated in a cell above this one.\n",
    "\n",
    "# 1. Retrieve your OpenAI API Key (ensure this is set)\n",
    "# Option A: From environment variable (if set before starting Jupyter)\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Option B: Paste your API key directly (less secure)\n",
    "# my_api_key = \"sk-your_actual_api_key_here\" \n",
    "\n",
    "# Option C: Prompt for the API key (more secure if typing it in)\n",
    "# import getpass\n",
    "# if not my_api_key:\n",
    "#     my_api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "if not my_api_key:\n",
    "    print(\"API Key not found. Please set it via environment variable or directly in the script.\", file=sys.stderr)\n",
    "else:\n",
    "    # Check if transcriptions_list exists and has content\n",
    "    if transcriptions_list:\n",
    "        # 2. Combine the list of transcriptions into a single string\n",
    "        # Using a double newline to separate distinct transcription parts,\n",
    "        # which can help the model understand them as separate utterances or segments.\n",
    "        full_transcription_text = \"\\n\\n\".join(transcriptions_list)\n",
    "        \n",
    "        print(f\"\\n--- Full Text to Summarize ({len(full_transcription_text.split())} words) ---\")\n",
    "        print(full_transcription_text) # Print a preview\n",
    "        print(\"--- End of Full Text ---\")\n",
    "\n",
    "        # 3. Specify the model for summarization (optional, defaults to \"gpt-3.5-turbo\")\n",
    "        # summarization_model = \"gpt-4\" # Or \"gpt-4o\" if you prefer and it's available\n",
    "        summarization_model = \"gpt-4.1\"\n",
    "\n",
    "        # 4. Call the summarization function\n",
    "        summary_text = summarize_text_openai(my_api_key, full_transcription_text, model=summarization_model)\n",
    "\n",
    "        # 5. Print the result\n",
    "        if summary_text:\n",
    "            print(\"\\n--- Generated Summary ---\")\n",
    "            print(summary_text)\n",
    "            print(\"--- End of Summary ---\")\n",
    "        else:\n",
    "            print(\"\\nSummarization failed. Please check the error messages above.\", file=sys.stderr)\n",
    "    else:\n",
    "        print(\"\\n'transcriptions_list' is not defined or is empty. Please ensure it contains text to summarize.\", file=sys.stderr)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
